{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ObjectDetection Faster R-CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMgBFkFp4Duuzt8oZKYAOMy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minukjeong/python/blob/main/ObjectDetection_Faster_R_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 명령어와 텐서플로우 허브 설치"
      ],
      "metadata": {
        "id": "SeKLZZNcJ4tf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aayDE04OFYbs"
      },
      "outputs": [],
      "source": [
        "# 시스템 명령어 처리\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "# 이미지 처리\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "\n",
        "# 파일 처리\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from six.moves.urllib.request import urlopen\n",
        "\n",
        "# 텐서플로우 허브\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사람 키포인트 튜플목록 불러오기 \n",
        "Faster R-CNN ResNet50 v1 640x640 사용"
      ],
      "metadata": {
        "id": "eNhOCTObKD7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run this!!\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  image = None\n",
        "  if(path.startswith('http')):\n",
        "    response = urlopen(path)\n",
        "    image_data = response.read()\n",
        "    image_data = BytesIO(image_data)\n",
        "    image = Image.open(image_data)\n",
        "  else:\n",
        "    image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(image_data))\n",
        "\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (1, im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "ALL_MODELS = {'Faster R-CNN ResNet50 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1'}\n",
        "\n",
        "COCO17_HUMAN_POSE_KEYPOINTS = [(0, 1),\n",
        " (0, 2),\n",
        " (1, 3),\n",
        " (2, 4),\n",
        " (0, 5),\n",
        " (0, 6),\n",
        " (5, 7),\n",
        " (7, 9),\n",
        " (6, 8),\n",
        " (8, 10),\n",
        " (5, 6),\n",
        " (5, 11),\n",
        " (6, 12),\n",
        " (11, 12),\n",
        " (11, 13),\n",
        " (13, 15),\n",
        " (12, 14),\n",
        " (14, 16)]"
      ],
      "metadata": {
        "id": "iGWssvi1FlB1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#시각화 도구\n",
        "적절하게 감지된 상자  키포인트 및 세분화로 이미지를 시각화하기 위해 TensorFlow Object Detection API를 사용합니다. 설치를 위해 리포지토리를 복제합니다."
      ],
      "metadata": {
        "id": "5KNg74nuKjeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2NHvCDHF8rU",
        "outputId": "1556aea4-77b2-469c-bd1e-04a8b476627a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3328, done.\u001b[K\n",
            "remote: Counting objects: 100% (3328/3328), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2753/2753), done.\u001b[K\n",
            "remote: Total 3328 (delta 882), reused 1387 (delta 525), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3328/3328), 34.31 MiB | 27.02 MiB/s, done.\n",
            "Resolving deltas: 100% (882/882), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#객체 인식 API 설치"
      ],
      "metadata": {
        "id": "JxtysJX8Kty8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 리눅스 명령어\n",
        "%%bash\n",
        "sudo apt install -y protobuf-compiler\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install -q ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arzjG3aPGAXM",
        "outputId": "76a94e9c-f736-4849-8598-8cde72729edd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "MjhE-X-3GC9r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#플로팅을 위해 레이블 맵 데이터 로드"
      ],
      "metadata": {
        "id": "R9lR8279K1CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ],
      "metadata": {
        "id": "mDkL7JLOGGsb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#감지 모델 빌드, 사정 훈련된 모델 가중치 로드"
      ],
      "metadata": {
        "id": "uQBvQYKnK8-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Selection { display-mode: \"form\", run: \"auto\" }\n",
        "model_display_name = 'Faster R-CNN ResNet50 V1 640x640' # @param ['CenterNet HourGlass104 512x512','CenterNet HourGlass104 Keypoints 512x512','CenterNet HourGlass104 1024x1024','CenterNet HourGlass104 Keypoints 1024x1024','CenterNet Resnet50 V1 FPN 512x512','CenterNet Resnet50 V1 FPN Keypoints 512x512','CenterNet Resnet101 V1 FPN 512x512','CenterNet Resnet50 V2 512x512','CenterNet Resnet50 V2 Keypoints 512x512','EfficientDet D0 512x512','EfficientDet D1 640x640','EfficientDet D2 768x768','EfficientDet D3 896x896','EfficientDet D4 1024x1024','EfficientDet D5 1280x1280','EfficientDet D6 1280x1280','EfficientDet D7 1536x1536','SSD MobileNet v2 320x320','SSD MobileNet V1 FPN 640x640','SSD MobileNet V2 FPNLite 320x320','SSD MobileNet V2 FPNLite 640x640','SSD ResNet50 V1 FPN 640x640 (RetinaNet50)','SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)','SSD ResNet101 V1 FPN 640x640 (RetinaNet101)','SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)','SSD ResNet152 V1 FPN 640x640 (RetinaNet152)','SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)','Faster R-CNN ResNet50 V1 640x640','Faster R-CNN ResNet50 V1 1024x1024','Faster R-CNN ResNet50 V1 800x1333','Faster R-CNN ResNet101 V1 640x640','Faster R-CNN ResNet101 V1 1024x1024','Faster R-CNN ResNet101 V1 800x1333','Faster R-CNN ResNet152 V1 640x640','Faster R-CNN ResNet152 V1 1024x1024','Faster R-CNN ResNet152 V1 800x1333','Faster R-CNN Inception ResNet V2 640x640','Faster R-CNN Inception ResNet V2 1024x1024','Mask R-CNN Inception ResNet V2 1024x1024']\n",
        "model_handle = ALL_MODELS[model_display_name]"
      ],
      "metadata": {
        "id": "OQ5maDRTGKZd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TensorFlow Hub 에서 선택한 모델 로드"
      ],
      "metadata": {
        "id": "O7UOpub-LGXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('loading model...')\n",
        "hub_model = hub.load(model_handle)\n",
        "print('model loaded!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VGN1JDLGPFb",
        "outputId": "31acb30a-a9b6-4c57-c5ef-307eed56a70d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model...\n",
            "model loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CV2 에러 방지를 위한 최신 업데이트"
      ],
      "metadata": {
        "id": "uwlM89roLQE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python-headless==4.5.2.52"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pALEPyTpHjkE",
        "outputId": "cfbc024b-9ace-4230-972c-1f555beafb8c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.21.6)\n",
            "Installing collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.5.5.64\n",
            "    Uninstalling opencv-python-headless-4.5.5.64:\n",
            "      Successfully uninstalled opencv-python-headless-4.5.5.64\n",
            "Successfully installed opencv-python-headless-4.5.2.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#영상 넣고 결과 영상 만들기"
      ],
      "metadata": {
        "id": "4w8VfUJzLbKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "video_input_path = \"/content/팔척귀신녀.mp4\"\n",
        "# linux에서 video output의 확장자는 반드시 avi 로 설정 필요. \n",
        "video_output_path = \"/content/영상고치기.avi\"\n",
        "\n",
        "# 동영상 불러오기\n",
        "cap = cv2.VideoCapture(video_input_path)\n",
        "\n",
        "# avi 코덱 선언\n",
        "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "# 동영상 이미지 가로 크기\n",
        "width = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "# 동영상 이미지 세로 크기\n",
        "height = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "# 동영상 초당 영상 재생 개수\n",
        "vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "# 동영상 저장용 선언\n",
        "vid_writer = cv2.VideoWriter(video_output_path, codec, vid_fps, vid_size) \n",
        "\n",
        "# 동영상 총 이미지 갯수=총 frame 갯수\n",
        "frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print('총 Frame 갯수:', frame_cnt)\n",
        "print('fps:',vid_fps)\n",
        "print('총 시간:', int(frame_cnt/vid_fps),'초 = ', int(frame_cnt/vid_fps/60),'분', int(frame_cnt/vid_fps)%60,'초')\n",
        "print('가로:', width, '세로:', height)\n",
        "\n",
        "# 동영상에서 불필요한 장면을 스킵 하기 위해서 비디오 시작지점을 설정한다.\n",
        "# cap.set(cv2.CAP_PROP_POS_FRAMES, 40*vid_fps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK8Pi22FGrqD",
        "outputId": "ea87476a-6282-4af2-866d-de3c06d237c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 Frame 갯수: 271\n",
            "fps: 30.0\n",
            "총 시간: 9 초 =  0 분 9 초\n",
            "가로: 406 세로: 720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "5w-sCWypGwgN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hub_model_result(image, _model):\n",
        "  # _model은 위에서 선택한 모델로 불러오도록 코드를 구성\n",
        "  # 선택한 모델로 찾을 image와 box와 labeling할 이미지  \n",
        "  start = time.time()\n",
        "  results = _model(image)\n",
        "  end = time.time()\n",
        "  print(end-start)\n",
        "\n",
        "  # different object detection models have additional results\n",
        "  # all of them are explained in the documentation\n",
        "  # tensorflow hub의 사용법은 모델의 결과값을 dict형태로 선언해서 사용하기 때문에 아래 형태로 선언\n",
        "  result = {key:value.numpy() for key,value in results.items()}\n",
        "  # 시작이 1 인지 0 인지 차이를 선언\n",
        "  label_id_offset = 0\n",
        "\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image[0],  # 함수 내부에서 원본 이미지의 크기 확인 및 화면에 그리는 이미지 선언\n",
        "                 # 모델 종류에 상관없이 이미지 크기는 원본 그대로 넣어도 된다.\n",
        "                 # 자동으로 /255 계산과, resize 코드가 내장되어 있다.\n",
        "                 # 원본 이미지값을 사용해야 나중에 화면에 표시할때 원본 크기로 계산할때 필요하기 때문\n",
        "      result['detection_boxes'][0],  # 사각형 좌표 들\n",
        "      (result['detection_classes'][0] + label_id_offset).astype(int),  # class 종류\n",
        "      result['detection_scores'][0],  # 각 사각형에 대한 object인 확률 (0~1 사이)\n",
        "      category_index,  # category 종류를 넣어주면 출력한 class 숫자를 category_index[class]로 출력해준다.\n",
        "      use_normalized_coordinates=True, # max_boxes_to_draw와 min_score_thresh 사용여부\n",
        "      max_boxes_to_draw=200,  # 최대 200개 까지 그린다.\n",
        "      min_score_thresh=.30,  # score값이 0.3 이하는 제거\n",
        "      agnostic_mode=False,  # True일 경우 score만 표시, clas 표시 안함, 기본은 False\n",
        "      # 아래는 해당 값이 있으면 사용함\n",
        "   ) \n",
        "  return image[0]"
      ],
      "metadata": {
        "id": "yfZu9D8zGyPI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_count = 0\n",
        "while True:\n",
        "  hasFrame, img_frame = cap.read()\n",
        "  print('frame count', frame_count)  \n",
        "  if not hasFrame:\n",
        "    print('더 이상 처리할 frame이 없습니다.')\n",
        "    break  \n",
        "\n",
        "  # hub_model에서는 이미지는 4체널로 선언해줘야 하기 때문에 앞에 1차원을 만들어줌\n",
        "  test_img = np.array(img_frame).reshape((1, height, width, 3)).astype(np.uint8)\n",
        "  # test_img : 테스트할 이미지, hub_model : 테스트할 모델\n",
        "  draw_img_frame  = get_hub_model_result(test_img, hub_model)\n",
        "  # 동영상중에서 1개의 frame 이미지를 진행했다는 count 표시용\n",
        "  frame_count += 1\n",
        "\n",
        "  # 아래는 확인용 코드\n",
        "  # plt.figure(figsize=(24,32))  # 크게 보고싶으면 코드 주석 제거\n",
        "  # plt.imshow(draw_img_frame)\n",
        "  # plt.show()\n",
        "  vid_writer.write(draw_img_frame)  \n",
        "\n",
        "  # 너무 많이 저장하면 오래걸리기 때문에 짧은 시간안에 테스트 할정도로 설정\n",
        "  if frame_count > 100: break  \n",
        "\n",
        "vid_writer.release()\n",
        "cap.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLAx2DlYG2Lj",
        "outputId": "476b11ac-67d2-42ea-a3e2-d75543ed97ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frame count 0\n",
            "12.293290853500366\n",
            "frame count 1\n",
            "4.236741542816162\n",
            "frame count 2\n",
            "4.327742576599121\n",
            "frame count 3\n",
            "4.178061485290527\n",
            "frame count 4\n",
            "4.260885238647461\n",
            "frame count 5\n",
            "4.297652244567871\n",
            "frame count 6\n",
            "4.251604318618774\n",
            "frame count 7\n",
            "4.3075830936431885\n",
            "frame count 8\n",
            "4.309257745742798\n",
            "frame count 9\n",
            "4.232635974884033\n",
            "frame count 10\n",
            "4.234773635864258\n",
            "frame count 11\n",
            "4.479790687561035\n",
            "frame count 12\n",
            "4.193079471588135\n",
            "frame count 13\n",
            "4.199892997741699\n",
            "frame count 14\n",
            "4.151808023452759\n",
            "frame count 15\n",
            "4.316534996032715\n",
            "frame count 16\n",
            "4.265373706817627\n",
            "frame count 17\n",
            "4.192974328994751\n",
            "frame count 18\n",
            "4.248050928115845\n",
            "frame count 19\n",
            "4.206481456756592\n",
            "frame count 20\n",
            "4.2756028175354\n",
            "frame count 21\n",
            "4.229045867919922\n",
            "frame count 22\n",
            "4.223596811294556\n",
            "frame count 23\n",
            "4.177287578582764\n",
            "frame count 24\n",
            "4.2590651512146\n",
            "frame count 25\n",
            "4.2052836418151855\n",
            "frame count 26\n",
            "4.206609010696411\n",
            "frame count 27\n",
            "4.3054327964782715\n",
            "frame count 28\n",
            "4.23715615272522\n",
            "frame count 29\n",
            "4.186382532119751\n",
            "frame count 30\n",
            "4.236104726791382\n",
            "frame count 31\n",
            "4.202663421630859\n",
            "frame count 32\n",
            "4.182152509689331\n",
            "frame count 33\n",
            "4.326370477676392\n",
            "frame count 34\n",
            "4.237210035324097\n",
            "frame count 35\n",
            "4.1933817863464355\n",
            "frame count 36\n",
            "4.268765211105347\n",
            "frame count 37\n",
            "4.298606872558594\n",
            "frame count 38\n",
            "4.193149566650391\n",
            "frame count 39\n",
            "4.2526092529296875\n",
            "frame count 40\n",
            "4.196038007736206\n",
            "frame count 41\n",
            "4.279422760009766\n",
            "frame count 42\n",
            "4.274848222732544\n",
            "frame count 43\n",
            "4.3410704135894775\n",
            "frame count 44\n",
            "4.3121654987335205\n",
            "frame count 45\n",
            "4.6299731731414795\n",
            "frame count 46\n",
            "5.230340003967285\n",
            "frame count 47\n",
            "4.266211986541748\n",
            "frame count 48\n",
            "4.235887289047241\n",
            "frame count 49\n",
            "4.22709059715271\n",
            "frame count 50\n",
            "4.284701824188232\n",
            "frame count 51\n",
            "4.309240818023682\n",
            "frame count 52\n",
            "4.314237594604492\n",
            "frame count 53\n",
            "4.281358957290649\n",
            "frame count 54\n",
            "4.309631109237671\n",
            "frame count 55\n",
            "4.243619680404663\n",
            "frame count 56\n",
            "4.282732009887695\n",
            "frame count 57\n",
            "4.2294862270355225\n",
            "frame count 58\n",
            "4.1973490715026855\n",
            "frame count 59\n",
            "4.308934450149536\n",
            "frame count 60\n",
            "4.312189817428589\n",
            "frame count 61\n",
            "4.256797552108765\n",
            "frame count 62\n",
            "4.339801073074341\n",
            "frame count 63\n",
            "4.295795917510986\n",
            "frame count 64\n",
            "4.242429971694946\n",
            "frame count 65\n",
            "4.197846412658691\n",
            "frame count 66\n",
            "4.26106071472168\n",
            "frame count 67\n",
            "4.193887233734131\n",
            "frame count 68\n",
            "4.208168029785156\n",
            "frame count 69\n",
            "4.233644723892212\n",
            "frame count 70\n",
            "4.176411390304565\n",
            "frame count 71\n",
            "4.294713258743286\n",
            "frame count 72\n",
            "4.3032636642456055\n",
            "frame count 73\n",
            "4.246670961380005\n",
            "frame count 74\n",
            "4.230895519256592\n",
            "frame count 75\n",
            "4.2709901332855225\n",
            "frame count 76\n",
            "4.247702360153198\n",
            "frame count 77\n",
            "4.261413812637329\n",
            "frame count 78\n",
            "4.21079158782959\n",
            "frame count 79\n",
            "4.25571346282959\n",
            "frame count 80\n",
            "4.201760530471802\n",
            "frame count 81\n",
            "4.303420305252075\n",
            "frame count 82\n",
            "4.194922685623169\n",
            "frame count 83\n",
            "4.247442960739136\n",
            "frame count 84\n",
            "4.35215163230896\n",
            "frame count 85\n",
            "4.2642786502838135\n",
            "frame count 86\n",
            "4.213987350463867\n",
            "frame count 87\n",
            "4.243868350982666\n",
            "frame count 88\n",
            "4.326291561126709\n",
            "frame count 89\n",
            "4.242993593215942\n",
            "frame count 90\n",
            "4.193629741668701\n",
            "frame count 91\n",
            "4.178993463516235\n",
            "frame count 92\n",
            "4.255051136016846\n",
            "frame count 93\n",
            "4.267856121063232\n",
            "frame count 94\n",
            "4.206914901733398\n",
            "frame count 95\n",
            "4.226381063461304\n",
            "frame count 96\n",
            "4.195786952972412\n",
            "frame count 97\n",
            "4.274820566177368\n",
            "frame count 98\n",
            "4.230785131454468\n",
            "frame count 99\n",
            "4.26741623878479\n",
            "frame count 100\n",
            "4.250489711761475\n"
          ]
        }
      ]
    }
  ]
}